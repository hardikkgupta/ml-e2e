# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lByrAGmCbAGSuXZIksITHbc4T7Z-nNxe
"""

import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
import joblib

dir = '/content/drive/MyDrive/data/'

def train_and_save_model():
    train_path = os.path.join(dir, 'train.csv')
    test_path = os.path.join(dir, 'test.csv')

    train_df = pd.read_csv(train_path)
    test_df = pd.read_csv(test_path)

    print("Training Data Shape:", train_df.shape)
    print("Test Data Shape:", test_df.shape)
    # print("\nMissing Values in Training Data:\n", train_df.isnull().sum())

    drop_columns = ['PassengerId', 'Name', 'Ticket', 'Cabin']
    # Dropping (drop_columns and 'Survived') columns
    X = train_df.drop(columns=drop_columns + ['Survived'])
    y = train_df['Survived']

    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
    print("\nNumerical Columns:", numerical_cols)
    print("Categorical Columns:", categorical_cols)

    numerical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])
    preprocessor = ColumnTransformer(transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', LogisticRegression(max_iter=1000))
    ])

    pipeline.fit(X, y)
    os.makedirs('app', exist_ok=True)
    model_path = os.path.join('app', 'model.pkl')
    joblib.dump(pipeline, model_path)
    print(f'Model saved to {model_path}')

    if 'Survived' in test_df.columns:
        evaluate_test_set(pipeline, test_df, drop_columns)
    else:
        print("\nTest labels (Survived column) not found. Preprocessing needed")

    # Optional: Generate predictions on test data for submission
    # generate_test_predictions(pipeline, test_df, drop_columns)

def evaluate_test_set(pipeline, test_df, drop_columns):
    # passenger_ids = test_df['PassengerId']

    X_test = test_df.drop(columns=drop_columns + ['Survived'])
    y_test = test_df['Survived']

    y_pred = pipeline.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f'\nTest Set Accuracy: {accuracy:.3f}')

# def generate_test_predictions(pipeline, test_df, drop_columns):
#     passenger_ids = test_df['PassengerId']

#     X_test = test_df.drop(columns=drop_columns + ['Survived'], errors='ignore')

#     predictions = pipeline.predict(X_test)

#     submission_df = pd.DataFrame({
#         'PassengerId': passenger_ids,
#         'Survived': predictions
#     })

#     submission_path = os.path.join('app', 'submission.csv')
#     submission_df.to_csv(submission_path, index=False)
#     print(f'\nTest Predictions saved to {submission_path}')

if __name__ == "__main__":
    train_and_save_model()

